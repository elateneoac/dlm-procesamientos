library(tidyverse)
library(tidytext)
library(stringi)
setwd(getwd())
list.files()
list.files("./data")
list.files("./noticias")
#defino los csv
list.files(path = "./noticias", pattern = "csv")
#defino los csv
archivos <- list.files(path = "./noticias", pattern = "csv")
#levanto todas las noticias en un solo df
for (i in archivos) {
df<-read.csv(i, encoding = "UTF-8")
base<-rbind(base, df)
}
df<-read.csv(paste0("./noticias/", i, encoding = "UTF-8")
base<-rbind(base, df)
}
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, "bullrich"))
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier")
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))
write.table(palabras, file = "palabras.csv", quote = F, row.names = F, sep = ";")
#levanto todas las noticias en un solo df
for (i in archivos) {
#levanto todas las noticias en un solo df
for (i in archivos) {
df<-read.csv(paste0("./noticias/", i, encoding = "UTF-8"))
base<-rbind(base, df)
}
df<-read.csv(paste0("./noticias/", i), encoding = "UTF-8")
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
# defino candidato
candidato<-"bullrich"
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
#creo un filtro de palabras que no quiero que salgan en el conteo
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
#creo un df vac√≠o
base<-data.frame()
#levanto todas las noticias en un solo df
for (i in archivos) {
df<-read.csv(paste0("./noticias/", i), encoding = "UTF-8")
base<-rbind(base, df)
}
# defino candidato
candidato<-"bullrich"
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
#creo un filtro de palabras que no quiero que salgan en el conteo
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier",
"anos", "dos")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))
View(palabras)
write.table(palabras, file = paste0("./resultados/", candidato, "_nubedepalabras_", Sys.Date(),".csv"), quote = F, row.names = F, sep = ";")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))%>%
slice(150)
write.table(palabras, file = paste0("./resultados/", candidato, "_nubedepalabras_", Sys.Date(),".csv"), quote = F, row.names = F, sep = ";")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))%>%
slice(1:150)
write.table(palabras, file = paste0("./resultados/", candidato, "_nubedepalabras_", Sys.Date(),".csv"), quote = F, row.names = F, sep = ";")
# defino candidato
candidato<-"massa"
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
#creo un filtro de palabras que no quiero que salgan en el conteo
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier",
"anos", "dos")
#creo un filtro de palabras que no quiero que salgan en el conteo
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier",
"anos", "dos")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))%>%
slice(1:150)
write.table(palabras, file = paste0("./resultados/", candidato, "_nubedepalabras_", Sys.Date(),".csv"), quote = F, row.names = F, sep = ";")
# defino candidato
candidato<-"bregman"
#limpio textos de noticias y filtro las que mencionan al candidato
noticias<-base%>%
mutate(
texto= str_to_lower(texto),
texto= stri_trans_general(texto, "Latin - ASCII"),
texto= str_replace_all(texto,"www\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto,"https\\S*", ""), #saco urls con REGEX
texto= str_replace_all(texto, "[[:punct:]]", " "),
texto= str_replace_all(texto, "[[:digit:]]+", " "))%>%
filter(str_detect(texto, candidato))
#creo un filtro de palabras que no quiero que salgan en el conteo
filtro_palabras<-c(stri_trans_general(stopwords::stopwords("es"), "Latin-ASCII"),
"patricia", "milei", "massa", "bullrich", "javier",
"anos", "dos")
#hago el conteo de palabras
palabras<-noticias%>%
unnest_tokens(input = texto, output = word)%>%
filter(!word %in% filtro_palabras)%>%
group_by(word)%>%
summarise(cantidad = n())%>%
arrange(desc(cantidad))%>%
slice(1:150)
write.table(palabras, file = paste0("./resultados/", candidato, "_nubedepalabras_", Sys.Date(),".csv"), quote = F, row.names = F, sep = ";")
